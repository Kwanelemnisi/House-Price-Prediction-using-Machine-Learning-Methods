---
title: "DECIPHERING THE INTRICATE RELATIONSHIPS WITHIN THE HOUSING MARKET"
author: "KN Mnisi"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Packages
```{r}
library(doBy)
library(dplyr)
library(readr)
library(corrplot)
library(RColorBrewer)
library(mice)
library(FactoMineR)
library(factoextra)
library(caret)
library(randomForest)
library(tibble)
library(ggplot2)
```

Importing the Ames Housing dataset.
```{r}
AmesHousing <- read_csv("AmesHousing.csv")
```
_________________________________________________________________________________________________________
SECTION 1: DATA ENGINEERING
_________________________________________________________________________________________________________

Calculating the number of NA (null) values and the percentage of NA values in each column. 
```{r}
Total_Na_Values <- colSums(is.na(AmesHousing))
Percentage <- floor(Total_Na_Values / nrow(AmesHousing) * 100)
NA_Counts <- cbind.data.frame(Total_Na_Values, Percentage)
```

Calculating the total number of variables that has NA values. 
```{r}
nonzero_rows <- sum(rowSums(NA_Counts != 0) > 0)
cat("There are", nonzero_rows, "variables containing NA values namely (Sorted in descending order):","\n")
nonzero_observations <- NA_Counts[rowSums(NA_Counts != 0) > 0, ]
(sorted_observations <- nonzero_observations[order(-nonzero_observations$Total_Na_Values), ])
```

There are numerous ways to deal with NA observations in a dataset.
*  Removing missing values: You can remove rows or columns with missing values from
   the dataset using the na.omit() or complete.cases() functions, respectively.
*  Replacing missing values: You can replace missing values with a value based on the 
   type of data. For example, you can replace missing numeric values with the mean or 
   median of the column, or replace missing categorical values with the mode etc.
*  Using imputation techniques: You can use more advanced imputation techniques to fill 
   in missing values. There are several R packages that provide imputation functions, 
   such as mice, missForest, and Amelia. 
   
Within the Ames dataset, there are five variables that contain a substantial number of missing values. These variables and their corresponding percentages of missing values are as follows: Alley (99%), Fire Place Qu (96%), Pool QC (93%), Fence (80%), Misc Feature (48%), and Lot Frontage (16%). Notably, the first four variables can be substituted with descriptive categories to indicate the absence of certain features. Specifically, "no alley access" (NAA), "no fireplace" (NFP), "no pool" (NP), and "no miscellaneous features" (NMF) respectively.  
```{r}
AmesHousing$Alley <- replace(AmesHousing$Alley, is.na(AmesHousing$Alley), "NAA")
AmesHousing$`Fireplace Qu` <- replace(AmesHousing$`Fireplace Qu`, 
                                      is.na(AmesHousing$`Fireplace Qu`), "NFP")
AmesHousing$`Pool QC` <- replace(AmesHousing$`Pool QC`, is.na(AmesHousing$`Pool QC`), "NP")
AmesHousing$Fence <- replace(AmesHousing$Fence, is.na(AmesHousing$Fence), "NF")
AmesHousing$`Misc Feature` <- replace(AmesHousing$`Misc Feature`, 
                                      is.na(AmesHousing$`Misc Feature`), "NMF")
```

The lot frontage variable cannot be replaced using such descriptive categories (as above) as there is no available information to determine the meaning behind the missing values. As a result, the imputation approach will be used to handle the missing values in the variable.
a) Removing spaces from variables for effective imputation.
```{r}
names(AmesHousing)[5] <- "LotFrontage"
names(AmesHousing)[6] <- "LotArea"
names(AmesHousing)[9] <- "LotShape"
names(AmesHousing)[4] <- "MSZoning"
names(AmesHousing)[12] <-"LotConfig"
```
b) Imputation is the done to address missing values in the "Lot Frontage" variable using the mice package. It uses predictive mean matching as the imputation method, running up to 50 iterations to generate one imputed dataset. The result is extracted in a long format, including both the original data and the imputed values, ensuring a comprehensive dataset with no missing values.
```{r}
vars <- c("LotFrontage", "LotArea", "LotShape", "Neighborhood", "MSZoning", "Street", "LotConfig")
dataset <- AmesHousing[, vars]
imp_model <- mice(dataset, method = "pmm", m = 1, maxit = 50)
imputed_data <- complete(imp_model, action = "long", include = TRUE)
AmesHousing$LotFrontage <- imputed_data$LotFrontage[2931:5860]
```
c) Returning the variables be its original format
```{r}
names(AmesHousing)[5] <- "Lot Frontage"
names(AmesHousing)[6] <- "Lot Area"
names(AmesHousing)[9] <- "Lot Shape"
names(AmesHousing)[4] <- "MS Zoning"
names(AmesHousing)[12] <- "Lot Config"
```

The presence of NA values in the garage-related variables, namely garage type (nominal), garage cond (ordinal), garage qual (nominal), garage finish (nominal), and garage yr blt (discrete), indicates the absence of a garage in the respective houses. It is worth noting that these variables collectively exhibit a consistent occurrence rate of 5% (157 values for every variable) for NA values. To address the missing values in the nominal and ordinal variables, a suitable approach is to substitute the NA values with the "no garage" (NG) category. This maintains consistency in the dataset and facilitates further analysis and interpretation. Regarding the garage yr built variable, the presence of null values signifies that the properties do not have garages. Since substituting these values with meaningful information is not feasible, a dummy variable named Has Garage is created. This variable takes the value 0 to represent "no garage" and 1 to indicate "garage present."
a) Removing the garage year built variable from the dataset. 
```{r}
AmesHousing <- subset(AmesHousing, select = -`Garage Yr Blt`)
```
b) Creating a dummy variable "Has Garage" that takes the value 0 to represent "no garage" and 1 to indicate "garage present".
```{r}
AmesHousing$`Has Garage` <- NA
AmesHousing$`Has Garage` <- ifelse(AmesHousing$`Garage Area` == 0, 0, 1)
```
c) Assign "NG" (No garage) to variables when `Has Garage` is 0
```{r}
AmesHousing$`Garage Type`[AmesHousing$`Has Garage` == 0] <- "NG"
AmesHousing$`Garage Cond`[AmesHousing$`Has Garage` == 0] <- "NG"
AmesHousing$`Garage Finish`[AmesHousing$`Has Garage` == 0] <- "NG"
AmesHousing$`Garage Qual`[AmesHousing$`Has Garage` == 0] <- "NG"
```

Among the basement-related variables in the dataset, several variables exhibit a consistent occurrence of 2% NA values. These variables include "bsmt exposure" (with 83 NA values), "bsmt qual" (with 80 NA values), "bsmt cond" (with 80 NA values), "bsmtfin type 1" (with 80 NA values), and "bsmtfin type 2" (with 81 NA values). It is worth noting that the number of NA values in each variable is not uniform, making it unwise to assume and replace all NA values with a generic category such as "no basement." Given the relatively insignificant percentage of NA values in these variables, it is reasonable to omit the NA values during analysis. This omission would lead to the elimination of the NA values in other basement-related variables, namely "bsmt full bath," "bsmt half bath," "bsmtfin sf 1," "bsmtfin sf 2," "bsmt unf sf," and "total bsmt sf."
Assing "NB" (No basement) to variables when `Total Bsmt SF` is 0.
```{r}
AmesHousing$`Bsmt Exposure`[AmesHousing$`Total Bsmt SF` == 0] <- "NB"
AmesHousing$`Bsmt Cond`[AmesHousing$`Total Bsmt SF` == 0] <- "NB"
AmesHousing$`Bsmt Qual`[AmesHousing$`Total Bsmt SF` == 0] <- "NB"
AmesHousing$`BsmtFin Type 1`[AmesHousing$`Total Bsmt SF` == 0] <- "NB"
AmesHousing$`BsmtFin Type 2`[AmesHousing$`Total Bsmt SF` == 0] <- "NB"
```

The "Mas Vnr Type" and "Mas Vnr Area" variables in the dataset have two missing values each, signifying the absence or unavailability of information regarding the type or area measurement of the masonry veneer for certain properties. Therefore, it is appropriate to remove these missing values from the dataset. Similarly, the "Electrical" variable has one missing value, suggesting missing or unavailable information about the type of electrical system in a specific house. This missing value can also be omitted from the analysis. Additionally, the "Garage Cars" and "Garage Area" variables each have one missing value, representing missing information related to the number of cars the garage can accommodate and the area of the garage, respectively. Omitting these missing values ensures data integrity and enables analysis based on complete and reliable information for the respective variables.

All other NA values present in the dataset, including the variables already discussed above that have NA observations remaining, is be omitted. 
```{r}
AmesHousing <- na.omit(AmesHousing)
Clean_AmesHousing <- AmesHousing
```
Now this is the cleaned dataset that will be used for the rest of the study.

______________________________________________________________________________________________________________
SECTION 2: DATA EXPLORATION
______________________________________________________________________________________________________________

Visualising a Box Plot.
```{r}
options(scipen = 999)
par(mar = c(5, 4, 4, 2)
    cex.axis = 0.6)
par(las = 1, yaxs = "i")
boxplot(AmesHousing$SalePrice,
        main = "Box Plot of Sale Price",
        ylab = "Sale Price",
        ylim = c(0,755000))
```
The box plot provides valuable insights into the distribution of house sale prices. It is apparent that the boxplot is skewed to the right. This skewness implies that the Ames housing market comprises a considerable number of moderately priced houses, while a smaller proportion of the market contains high-priced properties. The median sale price of $160 000 indicates the middle value, with half of the houses sold below this price and the other half above it. Moreover, the interquartile range (IQR) between $129 000 (1st Quartile, Q1) and $213,000 (3rd Quartile, Q3) represents the middle 50% of the data, offering an understanding of the typical range of sale prices. However, there are potential outliers, with the minimum sale price at $12 789 and the maximum at $755 000, indicating a few houses with exceptionally low or high sale prices compared to the majority of the data.

Extracting the outliers of the Sale Price variable from dataset  by using the z-scores approach.
```{r}
z_scores <- scale(AmesHousing$SalePrice)
outliers <- which(abs(z_scores) > 3)
outliers <- AmesHousing[outliers, ]
```
Based on the z-scores approach, a thorough analysis reveals the presence of 44 outliers within the Sale Price variable. While outliers often require careful consideration and treatment in data cleaning processes, this particular study refrains from addressing them during the initial dataset cleaning stage. This decision stems from the fact that the proposed algorithms employed in the study possess the ability to handle outliers, and furthermore, there exists a possibility that these outliers may hold valuable insights or unique characteristics worth exploring further.


Correlation Plot for all numeric variables in the Ames Dataset, excluding the "Order" Variable which is column 1.
```{r}
numeric_cols <- AmesHousing[sapply(AmesHousing, is.numeric)][,-1]
cor_matrix <- cor(numeric_cols)
corrplot(cor_matrix, method = "color",tl.cex = 0.5, col = colorRampPalette(brewer.pal(11, "RdYlBu"))(100))
```
The correlation heatmap reveals crucial insights into the dataset, showing the correlations between variables. Notably, there is a substantial positive correlation of 81.36% between Total Bsmt SF and 1st Flr SF, indicating that as the total basement area increases, so does the area on the first floor. Additionally, the correlation of 80.75% between TotRms AbvGrd and Gr Liv Area suggests that houses with more rooms above ground level tend to have larger ground living areas. Concerning the target variable, SalePrice, it exhibits a strong correlation with two key features. First, the Overall Qual) shows a correlation of 79.93%, implying that higher overall quality in a house is associated with higher sale prices. Second, the Gr Liv Area demonstrates a correlation of 70.86%, indicating that homes with larger ground living areas tend to achieve higher selling prices.


Calculating and analysing the mean sale price for every year. 
```{r}
Year_Sold <- AmesHousing$`Yr Sold`
Sale_Price <- AmesHousing$SalePrice
data <- data.frame(Year_Sold, Sale_Price)
(means <- aggregate(Sale_Price ~ Year_Sold, AmesHousing, mean))
```
The mean sale prices of houses in the Ames housing market from 2006 to 2010 showns an intriguing trend. The market experienced steady growth from 2006 to 2007, with the average sale price increasing from $180 879.60 to $184 728.70. This upswing can be attributed to a growing economy, increased housing demand, and possible inflationary pressures. However, in 2008, the average sale price slightly decreased to $178 587.30, which might be linked to the onset of the global financial crisis during that period, leading to a slowdown in the housing market. Despite the challenging financial crisis, the market exhibited resilience, rebounding to a mean sale price of $181 026.80 in 2009 and maintaining relative stability. In 2010, there was a more significant drop in the mean sale price to $172 323.80, which could be associated with the lingering effects of the financial crisis and the slower recovery process.


Checking how many variables will be optimal to use for our reduced model so that at least 80% of the variation in the response variable is explained. 
a) Creating a temporal dataset which is a duplicate of the AmesHousing dataset and transforming all variables to be numeric variables as it is required by the Principal Component Analysis (PCA) in order to determine the number of components (features) that explain at least 80% of the variation in the dataset
```{r}
pacdata <- AmesHousing
categorical_var <- names(pacdata %>%
                           select_if(is.character))
for (col in categorical_var) {
  pacdata[[col]] <- as.numeric(factor(pacdata[[col]]))
}
```
b) Perform PCA. The PCA (Principal Component Analysis) technique is used to reduce the dimensionality of a dataset while retaining at least a percentage (80% in this case) of its variation. It accomplishes this by transforming the original variables into a set of orthogonal principal components. The results, including principal components, eigenvalues, and variable loadings, are stored in `pca_result`, and graphical output is suppressed with `graph = FALSE` in the function call.
```{r}
pca_result <- PCA(AmesHousing[,!colnames(AmesHousing) %in% "SalePrice"] , graph = FALSE)
```
c) Determining the number of components to retain based on explained variance Finding the number of components that explain at least 80% of the variance
```{r}
explained_variance <- pca_result$eig[, 2]  # Percentage of variance explained
cumulative_variance <- cumsum(explained_variance)
optimal_num_variables <- which(cumulative_variance >= 80)[1]
cat(optimal_num_variables, "must be used for the reduced models in order to explain atleast 80% of the variance", "\n")
```
It has been ascertained by the PAC technique that utilizing 40 variables will yield the desired results, establishing it as the preferred number of features to be used for the reduced models.

